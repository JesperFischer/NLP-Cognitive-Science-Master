{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A quick intro to working with ```spaCy```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When ```spaCy``` is loaded, we then need to initialize a model.\n",
    "\n",
    "NB: Models first have to be downloaded from the command line. An overview of avaiable models from ```spaCy``` can be found [here](https://spacy.io/usage/models):\n",
    "\n",
    "```spacy download en_core_web_sm```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first create a ```spaCy``` pipeline which is going to be used for all of our analysis. Essentially we feed our examples of language down the pipeline, and get annotated texts out the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"My name is Ross and I come from Scotland\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final object that comes out of the end is known as a ```spaCy``` Doc which is essentiall a list of tokens. \n",
    "\n",
    "However, rather than just being a list of strings, each of the tokens in this list have their own *attributes*, which can be accessed using the dot notation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My \t\t PRON \t\t poss \t\t Number=Sing|Person=1|Poss=Yes|PronType=Prs\n",
      "name \t\t NOUN \t\t nsubj \t\t Number=Sing\n",
      "is \t\t AUX \t\t ROOT \t\t Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin\n",
      "Ross \t\t PROPN \t\t attr \t\t Number=Sing\n",
      "and \t\t CCONJ \t\t cc \t\t ConjType=Cmp\n",
      "I \t\t PRON \t\t nsubj \t\t Case=Nom|Number=Sing|Person=1|PronType=Prs\n",
      "come \t\t VERB \t\t conj \t\t Tense=Pres|VerbForm=Fin\n",
      "from \t\t ADP \t\t prep \t\t \n",
      "Scotland \t\t PROPN \t\t pobj \t\t Number=Sing\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text, \"\\t\\t\", token.pos_, \"\\t\\t\", token.dep_,\"\\t\\t\", token.morph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also visualise certain aspects of the linguistic structure of the sentence, such as the dependency relations between individual words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy.displacy.serve(doc, style=\"dep\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimenting\n",
    "\n",
    "- Experiment with different language models available from ```spaCy``` for another language you know - Danish, Dutch, Chinese, Portuguese, whatever.\n",
    "    - How does ```spaCy``` perform? \n",
    "    - Are all the same features available for all languages?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task\n",
    "\n",
    "- In the shared data drive, there is a folder called ```News_Category_Dataset_v2.json```. This is taken from [this Kaggle exercise](https://www.kaggle.com/datasets/rmisra/news-category-dataset) and comprises some 200k news headlines from [HuffPost](https://www.huffpost.com/). The data is a *json lines* format, with one JSON object per row. You can load this data into ```pandas``` in the following way:\n",
    "\n",
    "```python\n",
    "data = pd.read_json(filepath, lines=True)\n",
    "```\n",
    "\n",
    "- Select a couple of sub-categories of news data and use ```spaCy``` to find the **relative frequency per 10k words*** of each of the following word classes - NOUN, VERB, ADJECTIVE, ADVERB\n",
    "    - Save the results as a CSV file (again using ```pandas```)\n",
    "    - Are there any differences in the distributions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/work/115274/news_data\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "os.chdir(\"/work/115274/news_data\")\n",
    "print(os.getcwd())\n",
    "data = pd.read_json(\"News_Category_Dataset_v2.json\", lines = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Jets Chairman Christopher Johnson Won't Fine P...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Trump Posthumously Pardons Boxer Jack Johnson</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>Anna Kournikova Dancing With Her Bouncing Baby...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>Trump Says NFL Players Unwilling To Stand For ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>Brandi Chastain Totally Agrees Her Hall Of Fam...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200786</th>\n",
       "      <td>Thank You James Dolan and Time Warner</td>\n",
       "      <td>4879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200849</th>\n",
       "      <td>Maria Sharapova Stunned By Victoria Azarenka I...</td>\n",
       "      <td>4880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200850</th>\n",
       "      <td>Giants Over Patriots, Jets Over Colts Among  M...</td>\n",
       "      <td>4881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200851</th>\n",
       "      <td>Aldon Smith Arrested: 49ers Linebacker Busted ...</td>\n",
       "      <td>4882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200852</th>\n",
       "      <td>Dwight Howard Rips Teammates After Magic Loss ...</td>\n",
       "      <td>4883</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4884 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 headline     x\n",
       "80      Jets Chairman Christopher Johnson Won't Fine P...     0\n",
       "101         Trump Posthumously Pardons Boxer Jack Johnson     1\n",
       "135     Anna Kournikova Dancing With Her Bouncing Baby...     2\n",
       "136     Trump Says NFL Players Unwilling To Stand For ...     3\n",
       "154     Brandi Chastain Totally Agrees Her Hall Of Fam...     4\n",
       "...                                                   ...   ...\n",
       "200786              Thank You James Dolan and Time Warner  4879\n",
       "200849  Maria Sharapova Stunned By Victoria Azarenka I...  4880\n",
       "200850  Giants Over Patriots, Jets Over Colts Among  M...  4881\n",
       "200851  Aldon Smith Arrested: 49ers Linebacker Busted ...  4882\n",
       "200852  Dwight Howard Rips Teammates After Magic Loss ...  4883\n",
       "\n",
       "[4884 rows x 2 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sportsdata = data.loc[data[\"category\"] == \"SPORTS\"]\n",
    "\n",
    "\n",
    "headline = pd.DataFrame(sportsdata[\"headline\"])\n",
    "\n",
    "\n",
    "headline.assign(x = range(len(headline)))\n",
    "\n",
    "\n",
    "for i in range(3):\n",
    "    nlp(headline[i])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
